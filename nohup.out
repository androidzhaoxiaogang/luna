14:36:17.683 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
14:36:17.686 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
14:36:17.699 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
14:36:17.699 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
14:36:17.699 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
14:36:17.699 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
14:36:18.774 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: 59:18:33:f7:f0:fb:6a:9a
14:36:21.189 [main] INFO  elasticsearch - Get client!
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
14:36:21.193 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
14:36:21.283 [main] INFO  elasticsearch - Get client!
14:36:21.284 [main] INFO  kafka - threadnum: 4 and topicnum: 2
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
14:36:21.344 [pool-2-thread-1] INFO  kafka - Thread-49 Get kafka client!
14:36:21.347 [pool-2-thread-2] INFO  kafka - Thread-50 Get kafka client!
14:36:21.531 [pool-2-thread-1] INFO  kafka - Rebalance happened maxwell_xes_admin_op_logs:0
14:36:21.534 [pool-2-thread-2] INFO  kafka - Rebalance happened maxwell_xes_admin_permissions:0
17:44:49.773 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
17:44:50.744 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: 1f:d6:52:8a:40:98:b5:ea
17:44:51.086 [main] INFO  elasticsearch - Get client!
17:44:51.088 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
17:44:51.088 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
17:44:51.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
17:44:51.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
17:44:51.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
17:44:51.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
17:44:51.166 [main] INFO  elasticsearch - Get client!
17:44:51.168 [main] INFO  kafka - threadnum: 4 and topicnum: 4
17:44:51.196 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:44:51.244 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:44:51.244 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:44:51.246 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:44:51.247 [pool-2-thread-1] INFO  kafka - Thread-48 Get kafka client!
17:44:51.257 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:44:51.257 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:44:51.258 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:44:51.265 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:44:51.265 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:44:51.269 [pool-2-thread-2] INFO  kafka - Thread-49 Get kafka client!
17:44:51.271 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:44:51.275 [pool-2-thread-3] INFO  kafka - Thread-50 Get kafka client!
17:44:51.276 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:44:51.276 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:44:51.276 [pool-2-thread-4] INFO  kafka - Thread-51 Get kafka client!
17:44:51.452 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
17:44:51.453 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
17:44:51.454 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
17:44:51.454 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
17:44:51.456 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
17:44:51.456 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
17:44:51.456 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
17:44:51.456 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
17:44:51.457 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
17:44:51.457 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
17:44:51.457 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
17:44:51.457 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
17:44:51.482 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 3
17:44:51.482 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 3
17:44:51.483 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 3
17:44:51.483 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_plans-0] for group xes_dev_study
17:44:51.483 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_classes-0] for group xes_dev_study
17:44:51.483 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_op_logs-0] for group xes_dev_study
17:44:51.483 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 3
17:44:51.484 [pool-2-thread-3] INFO  kafka - Rebalance happened study_xes_student_live_op_logs:0
17:44:51.484 [pool-2-thread-4] INFO  kafka - Rebalance happened study_xes_student_live_plans:0
17:44:51.484 [pool-2-thread-2] INFO  kafka - Rebalance happened study_xes_student_live_classes:0
17:44:51.486 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_courses-0] for group xes_dev_study
17:44:51.486 [pool-2-thread-1] INFO  kafka - Rebalance happened study_xes_student_courses:0
17:52:16.035 [elasticsearch[_client_][generic][T#1]] INFO  org.elasticsearch.client.transport.TransportClientNodesService - failed to get local cluster state for {#transport#-1}{a1xql99wQjCKfP7GDjEOjQ}{10.97.14.81}{10.97.14.81:9300}, disconnecting...
org.elasticsearch.transport.NodeDisconnectedException: [][10.97.14.81:9300][cluster:monitor/state] disconnected
19:03:44.429 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
19:03:45.455 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: aa:29:99:a6:17:f3:40:8d
19:03:45.799 [main] INFO  elasticsearch - Get client!
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
19:03:45.884 [main] INFO  elasticsearch - Get client!
19:03:45.885 [main] INFO  kafka - threadnum: 4 and topicnum: 4
19:03:45.911 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

19:03:45.956 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
19:03:45.956 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
19:03:45.957 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

19:03:45.958 [pool-2-thread-1] INFO  kafka - Thread-48 Get kafka client!
19:03:45.970 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
19:03:45.970 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
19:03:45.971 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

19:03:45.974 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
19:03:45.974 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
19:03:45.974 [pool-2-thread-2] INFO  kafka - Thread-49 Get kafka client!
19:03:45.977 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

19:03:45.981 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
19:03:45.981 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
19:03:45.981 [pool-2-thread-3] INFO  kafka - Thread-50 Get kafka client!
19:03:45.982 [pool-2-thread-4] INFO  kafka - Thread-51 Get kafka client!
19:03:46.055 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
19:03:46.055 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
19:03:46.056 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
19:03:46.057 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
19:03:46.058 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
19:03:46.058 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
19:03:46.058 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.058 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.059 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
19:03:46.060 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.061 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
19:03:46.061 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.069 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.079 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 18
19:03:46.079 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 18
19:03:46.080 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_op_logs-0] for group xes_dev_study
19:03:46.080 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_plans-0] for group xes_dev_study
19:03:46.081 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 18
19:03:46.081 [pool-2-thread-3] INFO  kafka - Rebalance happened study_xes_student_live_op_logs:0
19:03:46.081 [pool-2-thread-4] INFO  kafka - Rebalance happened study_xes_student_live_plans:0
19:03:46.081 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_classes-0] for group xes_dev_study
19:03:46.081 [pool-2-thread-2] INFO  kafka - Rebalance happened study_xes_student_live_classes:0
19:03:46.083 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 18
19:03:46.083 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_courses-0] for group xes_dev_study
19:03:46.084 [pool-2-thread-1] INFO  kafka - Rebalance happened study_xes_student_courses:0
org.apache.kafka.clients.consumer.ConsumerRecords@73abf44b
19:03:46.152 [pool-2-thread-3] INFO  kafka - Thread-50: ConsumerRecord(topic = study_xes_student_live_op_logs, partition = 0, offset = 0, CreateTime = -1, serialized key size = 69, serialized value size = 391, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_live_op_logs","pk.id":18450}, value = {"database":"study","table":"xes_student_live_op_logs","type":"insert","ts":1505385672,"xid":72920872,"commit":true,"data":{"id":18450,"stu_id":11020,"stu_cou_id":4019020,"content":"{\"plan_id_from\":14917,\"plan_id_to\":\"14935\"}","controller":"App\\Component\\StuCourse\\StuCourse","action":"changeStuLivePlan","remark":"调场次","creater_id":11020,"create_time":"2017-09-14 18:41:25"}})
19:03:46.252 [pool-2-thread-3] INFO  elasticsearch - IndexResponse[index=xes_student_live_op_logs,type=study,id=18450,version=1,result=created,shards={"total":3,"successful":3,"failed":0}]
19:03:46.253 [pool-2-thread-3] INFO  time - xes_student_live_op_logs 18450 1354
19:03:46.253 [pool-2-thread-3] INFO  kafka - Thread-50: ConsumerRecord(topic = study_xes_student_live_op_logs, partition = 0, offset = 1, CreateTime = -1, serialized key size = 69, serialized value size = 391, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_live_op_logs","pk.id":18449}, value = {"database":"study","table":"xes_student_live_op_logs","type":"delete","ts":1505385775,"xid":72921465,"commit":true,"data":{"id":18449,"stu_id":11020,"stu_cou_id":4019020,"content":"{\"plan_id_from\":14935,\"plan_id_to\":\"14917\"}","controller":"App\\Component\\StuCourse\\StuCourse","action":"changeStuLivePlan","remark":"调场次","creater_id":11020,"create_time":"2017-09-14 17:32:38"}})
19:03:46.351 [pool-2-thread-3] INFO  elasticsearch - DeleteResponse[index=xes_student_live_op_logs,type=study,id=18449,version=1,result=not_found,shards=ShardInfo{total=3, successful=3, failures=[]}]
19:03:46.351 [pool-2-thread-3] INFO  time - xes_student_live_op_logs 18449 1251
19:03:46.352 [pool-2-thread-3] INFO  kafka - Thread-50: ConsumerRecord(topic = study_xes_student_live_op_logs, partition = 0, offset = 2, CreateTime = -1, serialized key size = 69, serialized value size = 391, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_live_op_logs","pk.id":18443}, value = {"database":"study","table":"xes_student_live_op_logs","type":"delete","ts":1505385775,"xid":72921466,"commit":true,"data":{"id":18443,"stu_id":11020,"stu_cou_id":4019020,"content":"{\"plan_id_from\":14917,\"plan_id_to\":\"14935\"}","controller":"App\\Component\\StuCourse\\StuCourse","action":"changeStuLivePlan","remark":"调场次","creater_id":11020,"create_time":"2017-09-13 21:13:15"}})
19:03:46.406 [pool-2-thread-3] INFO  elasticsearch - DeleteResponse[index=xes_student_live_op_logs,type=study,id=18443,version=2,result=deleted,shards=ShardInfo{total=3, successful=3, failures=[]}]
19:03:46.407 [pool-2-thread-3] INFO  time - xes_student_live_op_logs 18443 1251
19:03:46.407 [pool-2-thread-3] INFO  kafka - Thread-50: ConsumerRecord(topic = study_xes_student_live_op_logs, partition = 0, offset = 3, CreateTime = -1, serialized key size = 69, serialized value size = 395, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_live_op_logs","pk.id":11084}, value = {"database":"study","table":"xes_student_live_op_logs","type":"delete","ts":1505385775,"xid":72921467,"commit":true,"data":{"id":11084,"stu_id":11020,"stu_cou_id":4019020,"content":"{\"plan_id_from\":\"14917\",\"plan_id_to\":\"14935\"}","controller":"App\\Component\\StuCourse\\StuCourse","action":"changeStuLivePlan","remark":"调场次","creater_id":11020,"create_time":"2017-09-05 17:56:39"}})
19:03:46.453 [pool-2-thread-3] INFO  elasticsearch - DeleteResponse[index=xes_student_live_op_logs,type=study,id=11084,version=2,result=deleted,shards=ShardInfo{total=3, successful=3, failures=[]}]
19:03:46.453 [pool-2-thread-3] INFO  time - xes_student_live_op_logs 11084 1251
16:47:08.151 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
16:47:08.154 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
16:47:08.155 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
16:47:08.155 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
16:47:08.155 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
16:47:08.155 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
16:47:09.212 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: 2d:21:f6:ef:60:ae:bc:66
16:47:09.598 [main] INFO  elasticsearch - Get client!
16:47:09.601 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
16:47:09.601 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
16:47:09.601 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
16:47:09.601 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
16:47:09.601 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
16:47:09.601 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
16:47:09.674 [main] INFO  elasticsearch - Get client!
16:47:09.676 [main] INFO  kafka - threadnum: 4 and topicnum: 4
16:47:09.699 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

16:47:09.743 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
16:47:09.744 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
16:47:09.861 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

16:47:09.861 [pool-2-thread-1] INFO  kafka - Thread-49 Get kafka client!
16:47:09.865 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
16:47:09.865 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
16:47:09.866 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

16:47:09.866 [pool-2-thread-2] INFO  kafka - Thread-50 Get kafka client!
16:47:09.870 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
16:47:09.870 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
16:47:09.871 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

16:47:09.872 [pool-2-thread-3] INFO  kafka - Thread-51 Get kafka client!
16:47:09.876 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
16:47:09.876 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
16:47:09.877 [pool-2-thread-4] INFO  kafka - Thread-52 Get kafka client!
16:47:09.936 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
16:47:09.936 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
16:47:09.936 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
16:47:09.938 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
16:47:09.938 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
16:47:09.938 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
16:47:09.938 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
16:47:09.938 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
16:47:09.939 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
16:47:09.939 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
16:47:09.940 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
16:47:09.940 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
16:47:09.952 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
16:47:09.958 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
16:47:09.965 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 4
16:47:09.965 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 4
16:47:09.965 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 4
16:47:09.965 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 4
16:47:09.966 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_op_logs-0] for group xes_dev_study_test
16:47:09.966 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_courses-0] for group xes_dev_study_test
16:47:09.967 [pool-2-thread-3] INFO  kafka - Rebalance happened study_test_xes_student_live_op_logs:0
16:47:09.967 [pool-2-thread-1] INFO  kafka - Rebalance happened study_test_xes_student_courses:0
16:47:09.967 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_plans-0] for group xes_dev_study_test
16:47:09.967 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_classes-0] for group xes_dev_study_test
16:47:09.967 [pool-2-thread-2] INFO  kafka - Rebalance happened study_test_xes_student_live_classes:0
16:47:09.967 [pool-2-thread-4] INFO  kafka - Rebalance happened study_test_xes_student_live_plans:0
17:19:07.787 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
17:19:07.790 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
17:19:07.790 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
17:19:07.790 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
17:19:07.790 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
17:19:07.790 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
17:19:08.774 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: 17:58:cf:a7:5b:77:4c:61
17:19:09.086 [main] INFO  elasticsearch - Get client!
17:19:09.089 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
17:19:09.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
17:19:09.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
17:19:09.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
17:19:09.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
17:19:09.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
17:19:09.168 [main] INFO  elasticsearch - Get client!
17:19:09.169 [main] INFO  kafka - threadnum: 4 and topicnum: 4
17:19:09.196 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:19:09.246 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:19:09.246 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:19:09.249 [pool-2-thread-1] INFO  kafka - Thread-50 Get kafka client!
17:19:09.252 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:19:09.259 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:19:09.259 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:19:09.260 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:19:09.262 [pool-2-thread-2] INFO  kafka - Thread-51 Get kafka client!
17:19:09.264 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:19:09.264 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:19:09.265 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:19:09.267 [pool-2-thread-3] INFO  kafka - Thread-52 Get kafka client!
17:19:09.268 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:19:09.268 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:19:09.269 [pool-2-thread-4] INFO  kafka - Thread-53 Get kafka client!
17:19:09.341 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
17:19:09.341 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
17:19:09.342 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
17:19:09.342 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
17:19:09.344 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
17:19:09.344 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
17:19:09.344 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
17:19:09.344 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
17:19:09.344 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
17:19:09.344 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
17:19:09.348 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
17:19:09.348 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
17:19:09.354 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
17:19:09.359 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
17:19:09.364 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 7
17:19:09.364 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 7
17:19:09.364 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 7
17:19:09.365 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_op_logs-0] for group xes_dev_study_test
17:19:09.365 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_plans-0] for group xes_dev_study_test
17:19:09.365 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_classes-0] for group xes_dev_study_test
17:19:09.365 [pool-2-thread-2] INFO  kafka - Rebalance happened study_test_xes_student_live_classes:0
17:19:09.366 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 7
17:19:09.366 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_courses-0] for group xes_dev_study_test
17:19:09.366 [pool-2-thread-1] INFO  kafka - Rebalance happened study_test_xes_student_courses:0
17:19:09.365 [pool-2-thread-4] INFO  kafka - Rebalance happened study_test_xes_student_live_plans:0
17:19:09.367 [pool-2-thread-3] INFO  kafka - Rebalance happened study_test_xes_student_live_op_logs:0
17:20:57.190 [pool-2-thread-1] INFO  kafka - Thread-50: ConsumerRecord(topic = study_test_xes_student_courses, partition = 0, offset = 0, CreateTime = -1, serialized key size = 60, serialized value size = 531, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_courses","pk.id":1}, value = {"database":"study","table":"xes_student_courses","type":"insert","ts":1505985630,"xid":48004,"commit":true,"data":{"id":1,"stu_id":10016,"uid":10016,"order_num":"201601140650426436","product_id":0,"course_id":36472,"course_name":"14号内部测！试用直播课程","category":7,"outline_ids":"2","subject_ids":"2","start_time":"2016-01-14","end_time":"2016-01-31","current_lastend_time":"2016-01-31","sys_delay_day":0,"real_price":1000.00,"return_type":2,"create_time":"2016-01-14 06:50:36","modify_time":"2017-09-05 15:26:31"}})
17:20:57.199 [pool-2-thread-1] ERROR kafka - Thread 50: java.lang.NullPointerException
17:20:57.206 [pool-2-thread-1] INFO  kafka - Consumer Thread 50is closed!
17:20:57.482 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [study_test_xes_student_live_plans-0] for group xes_dev_study_test
17:20:57.482 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
17:20:57.482 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [study_test_xes_student_live_classes-0] for group xes_dev_study_test
17:20:57.483 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
17:20:57.484 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [study_test_xes_student_live_op_logs-0] for group xes_dev_study_test
17:20:57.485 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
17:20:57.838 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 8
17:20:57.838 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 8
17:20:57.838 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_op_logs-0] for group xes_dev_study_test
17:20:57.838 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_classes-0] for group xes_dev_study_test
17:20:57.839 [pool-2-thread-2] INFO  kafka - Rebalance happened study_test_xes_student_live_classes:0
17:20:57.839 [pool-2-thread-3] INFO  kafka - Rebalance happened study_test_xes_student_live_op_logs:0
17:20:57.839 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 8
17:20:57.839 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_plans-0] for group xes_dev_study_test
17:20:57.840 [pool-2-thread-4] INFO  kafka - Rebalance happened study_test_xes_student_live_plans:0
18:56:17.660 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
18:56:17.663 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
18:56:17.663 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
18:56:17.663 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
18:56:17.663 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
18:56:17.663 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
18:56:18.737 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: 1f:c0:2f:d3:f6:76:04:01
18:56:19.122 [main] INFO  elasticsearch - Get client!
18:56:19.124 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
18:56:19.125 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
18:56:19.125 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
18:56:19.125 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
18:56:19.125 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
18:56:19.125 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
18:56:19.188 [main] INFO  elasticsearch - Get client!
18:56:19.189 [main] INFO  kafka - threadnum: 4 and topicnum: 4
18:56:19.213 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

18:56:19.262 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
18:56:19.262 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
18:56:19.266 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

18:56:19.267 [pool-2-thread-1] INFO  kafka - Thread-49 Get kafka client!
18:56:19.276 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
18:56:19.277 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
18:56:19.277 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

18:56:19.281 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
18:56:19.281 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
18:56:19.285 [pool-2-thread-2] INFO  kafka - Thread-50 Get kafka client!
18:56:19.285 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

18:56:19.291 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
18:56:19.291 [pool-2-thread-3] INFO  kafka - Thread-51 Get kafka client!
18:56:19.291 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
18:56:19.293 [pool-2-thread-4] INFO  kafka - Thread-52 Get kafka client!
18:56:19.372 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
18:56:19.372 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
18:56:19.372 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
18:56:19.373 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study_test.
18:56:19.375 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
18:56:19.375 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
18:56:19.375 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
18:56:19.375 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
18:56:19.376 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
18:56:19.376 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
18:56:19.376 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
18:56:19.377 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
18:56:19.386 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
18:56:19.397 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 40
18:56:19.397 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 40
18:56:19.398 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 40
18:56:19.399 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 40
18:56:19.399 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_classes-0] for group xes_dev_study_test
18:56:19.399 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_plans-0] for group xes_dev_study_test
18:56:19.399 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_op_logs-0] for group xes_dev_study_test
18:56:19.399 [pool-2-thread-2] INFO  kafka - Rebalance happened study_test_xes_student_live_classes:0
18:56:19.399 [pool-2-thread-4] INFO  kafka - Rebalance happened study_test_xes_student_live_plans:0
18:56:19.399 [pool-2-thread-3] INFO  kafka - Rebalance happened study_test_xes_student_live_op_logs:0
18:56:19.401 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_courses-0] for group xes_dev_study_test
18:56:19.401 [pool-2-thread-1] INFO  kafka - Rebalance happened study_test_xes_student_courses:0
18:57:11.500 [pool-2-thread-1] INFO  kafka - Thread-49: ConsumerRecord(topic = study_test_xes_student_courses, partition = 0, offset = 8, CreateTime = -1, serialized key size = 60, serialized value size = 531, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_courses","pk.id":8}, value = {"database":"study","table":"xes_student_courses","type":"delete","ts":1505991405,"xid":51170,"commit":true,"data":{"id":8,"stu_id":10016,"uid":10016,"order_num":"201601140650426436","product_id":0,"course_id":36472,"course_name":"14号内部测！试用直播课程","category":7,"outline_ids":"2","subject_ids":"2","start_time":"2016-01-14","end_time":"2016-01-31","current_lastend_time":"2016-01-31","sys_delay_day":0,"real_price":1000.00,"return_type":2,"create_time":"2016-01-14 06:50:36","modify_time":"2017-09-05 15:26:31"}})
18:57:11.570 [pool-2-thread-1] INFO  elasticsearch - DeleteResponse[index=xes_student_courses,type=study_test,id=8,version=2,result=deleted,shards=ShardInfo{total=3, successful=3, failures=[]}]
18:57:11.571 [pool-2-thread-1] INFO  time - xes_student_courses 8 26
10:12:21.926 [pool-2-thread-1] INFO  kafka - Thread-49: ConsumerRecord(topic = study_test_xes_student_courses, partition = 0, offset = 9, CreateTime = -1, serialized key size = 60, serialized value size = 531, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_courses","pk.id":7}, value = {"database":"study","table":"xes_student_courses","type":"delete","ts":1506046315,"xid":59817,"commit":true,"data":{"id":7,"stu_id":10016,"uid":10016,"order_num":"201601140650426436","product_id":0,"course_id":36472,"course_name":"14号内部测！试用直播课程","category":7,"outline_ids":"2","subject_ids":"2","start_time":"2016-01-14","end_time":"2016-01-31","current_lastend_time":"2016-01-31","sys_delay_day":0,"real_price":1000.00,"return_type":2,"create_time":"2016-01-14 06:50:36","modify_time":"2017-09-05 15:26:31"}})
10:12:22.007 [pool-2-thread-1] INFO  elasticsearch - DeleteResponse[index=xes_student_courses,type=study_test,id=7,version=1,result=not_found,shards=ShardInfo{total=3, successful=3, failures=[]}]
10:12:22.016 [pool-2-thread-1] INFO  time - xes_student_courses 7 27
10:12:26.541 [pool-2-thread-1] INFO  kafka - Thread-49: ConsumerRecord(topic = study_test_xes_student_courses, partition = 0, offset = 10, CreateTime = -1, serialized key size = 60, serialized value size = 531, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_courses","pk.id":6}, value = {"database":"study","table":"xes_student_courses","type":"delete","ts":1506046320,"xid":59821,"commit":true,"data":{"id":6,"stu_id":10016,"uid":10016,"order_num":"201601140650426436","product_id":0,"course_id":36472,"course_name":"14号内部测！试用直播课程","category":7,"outline_ids":"2","subject_ids":"2","start_time":"2016-01-14","end_time":"2016-01-31","current_lastend_time":"2016-01-31","sys_delay_day":0,"real_price":1000.00,"return_type":2,"create_time":"2016-01-14 06:50:36","modify_time":"2017-09-05 15:26:31"}})
10:12:26.601 [pool-2-thread-1] INFO  elasticsearch - DeleteResponse[index=xes_student_courses,type=study_test,id=6,version=1,result=not_found,shards=ShardInfo{total=3, successful=3, failures=[]}]
10:12:26.601 [pool-2-thread-1] INFO  time - xes_student_courses 6 26
10:12:31.584 [pool-2-thread-1] INFO  kafka - Thread-49: ConsumerRecord(topic = study_test_xes_student_courses, partition = 0, offset = 11, CreateTime = -1, serialized key size = 60, serialized value size = 531, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_courses","pk.id":5}, value = {"database":"study","table":"xes_student_courses","type":"delete","ts":1506046325,"xid":59825,"commit":true,"data":{"id":5,"stu_id":10016,"uid":10016,"order_num":"201601140650426436","product_id":0,"course_id":36472,"course_name":"14号内部测！试用直播课程","category":7,"outline_ids":"2","subject_ids":"2","start_time":"2016-01-14","end_time":"2016-01-31","current_lastend_time":"2016-01-31","sys_delay_day":0,"real_price":1000.00,"return_type":2,"create_time":"2016-01-14 06:50:36","modify_time":"2017-09-05 15:26:31"}})
10:12:31.635 [pool-2-thread-1] INFO  elasticsearch - DeleteResponse[index=xes_student_courses,type=study_test,id=5,version=1,result=not_found,shards=ShardInfo{total=3, successful=3, failures=[]}]
10:12:31.635 [pool-2-thread-1] INFO  time - xes_student_courses 5 26
10:12:36.594 [pool-2-thread-1] INFO  kafka - Thread-49: ConsumerRecord(topic = study_test_xes_student_courses, partition = 0, offset = 12, CreateTime = -1, serialized key size = 60, serialized value size = 531, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_courses","pk.id":3}, value = {"database":"study","table":"xes_student_courses","type":"delete","ts":1506046330,"xid":59829,"commit":true,"data":{"id":3,"stu_id":10016,"uid":10016,"order_num":"201601140650426436","product_id":0,"course_id":36472,"course_name":"14号内部测！试用直播课程","category":7,"outline_ids":"2","subject_ids":"2","start_time":"2016-01-14","end_time":"2016-01-31","current_lastend_time":"2016-01-31","sys_delay_day":0,"real_price":1000.00,"return_type":2,"create_time":"2016-01-14 06:50:36","modify_time":"2017-09-05 15:26:31"}})
10:12:36.650 [pool-2-thread-1] INFO  elasticsearch - DeleteResponse[index=xes_student_courses,type=study_test,id=3,version=1,result=not_found,shards=ShardInfo{total=3, successful=3, failures=[]}]
10:12:36.651 [pool-2-thread-1] INFO  time - xes_student_courses 3 26
10:12:40.538 [pool-2-thread-1] INFO  kafka - Thread-49: ConsumerRecord(topic = study_test_xes_student_courses, partition = 0, offset = 13, CreateTime = -1, serialized key size = 60, serialized value size = 531, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_courses","pk.id":4}, value = {"database":"study","table":"xes_student_courses","type":"delete","ts":1506046334,"xid":59833,"commit":true,"data":{"id":4,"stu_id":10016,"uid":10016,"order_num":"201601140650426436","product_id":0,"course_id":36472,"course_name":"14号内部测！试用直播课程","category":7,"outline_ids":"2","subject_ids":"2","start_time":"2016-01-14","end_time":"2016-01-31","current_lastend_time":"2016-01-31","sys_delay_day":0,"real_price":1000.00,"return_type":2,"create_time":"2016-01-14 06:50:36","modify_time":"2017-09-05 15:26:31"}})
10:12:40.597 [pool-2-thread-1] INFO  elasticsearch - DeleteResponse[index=xes_student_courses,type=study_test,id=4,version=1,result=not_found,shards=ShardInfo{total=3, successful=3, failures=[]}]
10:12:40.597 [pool-2-thread-1] INFO  time - xes_student_courses 4 26
10:12:44.440 [pool-2-thread-1] INFO  kafka - Thread-49: ConsumerRecord(topic = study_test_xes_student_courses, partition = 0, offset = 14, CreateTime = -1, serialized key size = 60, serialized value size = 531, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_courses","pk.id":2}, value = {"database":"study","table":"xes_student_courses","type":"delete","ts":1506046338,"xid":59837,"commit":true,"data":{"id":2,"stu_id":10016,"uid":10016,"order_num":"201601140650426436","product_id":0,"course_id":36472,"course_name":"14号内部测！试用直播课程","category":7,"outline_ids":"2","subject_ids":"2","start_time":"2016-01-14","end_time":"2016-01-31","current_lastend_time":"2016-01-31","sys_delay_day":0,"real_price":1000.00,"return_type":2,"create_time":"2016-01-14 06:50:36","modify_time":"2017-09-05 15:26:31"}})
10:12:44.491 [pool-2-thread-1] INFO  elasticsearch - DeleteResponse[index=xes_student_courses,type=study_test,id=2,version=1,result=not_found,shards=ShardInfo{total=3, successful=3, failures=[]}]
10:12:44.491 [pool-2-thread-1] INFO  time - xes_student_courses 2 26
10:12:48.543 [pool-2-thread-1] INFO  kafka - Thread-49: ConsumerRecord(topic = study_test_xes_student_courses, partition = 0, offset = 15, CreateTime = -1, serialized key size = 60, serialized value size = 531, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_courses","pk.id":1}, value = {"database":"study","table":"xes_student_courses","type":"delete","ts":1506046342,"xid":59841,"commit":true,"data":{"id":1,"stu_id":10016,"uid":10016,"order_num":"201601140650426436","product_id":0,"course_id":36472,"course_name":"14号内部测！试用直播课程","category":7,"outline_ids":"2","subject_ids":"2","start_time":"2016-01-14","end_time":"2016-01-31","current_lastend_time":"2016-01-31","sys_delay_day":0,"real_price":1000.00,"return_type":2,"create_time":"2016-01-14 06:50:36","modify_time":"2017-09-05 15:26:31"}})
10:12:48.599 [pool-2-thread-1] INFO  elasticsearch - DeleteResponse[index=xes_student_courses,type=study_test,id=1,version=1,result=not_found,shards=ShardInfo{total=3, successful=3, failures=[]}]
10:12:48.599 [pool-2-thread-1] INFO  time - xes_student_courses 1 26
10:20:20.453 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
10:20:20.456 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
10:20:20.456 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
10:20:20.456 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
10:20:20.456 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
10:20:20.456 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
10:20:21.510 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: 6c:77:7f:f0:c8:31:87:df
10:20:21.921 [main] INFO  elasticsearch - Get client!
10:20:21.923 [main] INFO  kafka - threadnum: 4 and topicnum: 4
10:20:21.962 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = PLAIN
	security.protocol = SASL_PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

10:20:22.050 [main] INFO  org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
10:20:22.090 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
10:20:22.090 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
10:20:22.091 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = PLAIN
	security.protocol = SASL_PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

10:20:22.094 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
10:20:22.094 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
10:20:22.095 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = PLAIN
	security.protocol = SASL_PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

10:20:22.095 [pool-2-thread-2] INFO  kafka - Thread-31 Get kafka client!
10:20:22.098 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
10:20:22.098 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
10:20:22.099 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study_test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = PLAIN
	security.protocol = SASL_PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

10:20:22.102 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
10:20:22.102 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
10:20:22.102 [pool-2-thread-3] INFO  kafka - Thread-32 Get kafka client!
10:20:22.104 [pool-2-thread-1] INFO  kafka - Thread-30 Get kafka client!
10:20:22.107 [pool-2-thread-4] INFO  kafka - Thread-33 Get kafka client!
10:20:22.202 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.67:9092 (id: 2147483647 rack: null) for group xes_dev_study_test.
10:20:22.202 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.67:9092 (id: 2147483647 rack: null) for group xes_dev_study_test.
10:20:22.202 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.67:9092 (id: 2147483647 rack: null) for group xes_dev_study_test.
10:20:22.202 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.67:9092 (id: 2147483647 rack: null) for group xes_dev_study_test.
10:20:22.206 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
10:20:22.206 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
10:20:22.206 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
10:20:22.206 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
10:20:22.206 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
10:20:22.207 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
10:20:22.207 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study_test
10:20:22.207 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
10:20:22.222 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study_test
10:20:22.241 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 5
10:20:22.241 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 5
10:20:22.241 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 5
10:20:22.242 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_op_logs-0] for group xes_dev_study_test
10:20:22.242 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_plans-0] for group xes_dev_study_test
10:20:22.242 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_live_classes-0] for group xes_dev_study_test
10:20:22.243 [pool-2-thread-2] INFO  kafka - Rebalance happened study_test_xes_student_live_classes:0
10:20:22.243 [pool-2-thread-3] INFO  kafka - Rebalance happened study_test_xes_student_live_op_logs:0
10:20:22.243 [pool-2-thread-4] INFO  kafka - Rebalance happened study_test_xes_student_live_plans:0
10:20:22.244 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study_test with generation 5
10:20:22.245 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_test_xes_student_courses-0] for group xes_dev_study_test
10:20:22.245 [pool-2-thread-1] INFO  kafka - Rebalance happened study_test_xes_student_courses:0
