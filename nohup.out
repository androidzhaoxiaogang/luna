14:36:17.683 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
14:36:17.686 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
14:36:17.699 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
14:36:17.699 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
14:36:17.699 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
14:36:17.699 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
14:36:18.774 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: 59:18:33:f7:f0:fb:6a:9a
14:36:21.189 [main] INFO  elasticsearch - Get client!
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
14:36:21.192 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
14:36:21.193 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
14:36:21.283 [main] INFO  elasticsearch - Get client!
14:36:21.284 [main] INFO  kafka - threadnum: 4 and topicnum: 2
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
14:36:21.344 [pool-2-thread-1] INFO  kafka - Thread-49 Get kafka client!
14:36:21.347 [pool-2-thread-2] INFO  kafka - Thread-50 Get kafka client!
14:36:21.531 [pool-2-thread-1] INFO  kafka - Rebalance happened maxwell_xes_admin_op_logs:0
14:36:21.534 [pool-2-thread-2] INFO  kafka - Rebalance happened maxwell_xes_admin_permissions:0
17:44:49.773 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
17:44:49.777 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
17:44:50.744 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: 1f:d6:52:8a:40:98:b5:ea
17:44:51.086 [main] INFO  elasticsearch - Get client!
17:44:51.088 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
17:44:51.088 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
17:44:51.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
17:44:51.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
17:44:51.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
17:44:51.089 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
17:44:51.166 [main] INFO  elasticsearch - Get client!
17:44:51.168 [main] INFO  kafka - threadnum: 4 and topicnum: 4
17:44:51.196 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:44:51.244 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:44:51.244 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:44:51.246 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:44:51.247 [pool-2-thread-1] INFO  kafka - Thread-48 Get kafka client!
17:44:51.257 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:44:51.257 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:44:51.258 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:44:51.265 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:44:51.265 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:44:51.269 [pool-2-thread-2] INFO  kafka - Thread-49 Get kafka client!
17:44:51.271 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:44:51.275 [pool-2-thread-3] INFO  kafka - Thread-50 Get kafka client!
17:44:51.276 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
17:44:51.276 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
17:44:51.276 [pool-2-thread-4] INFO  kafka - Thread-51 Get kafka client!
17:44:51.452 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
17:44:51.453 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
17:44:51.454 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
17:44:51.454 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
17:44:51.456 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
17:44:51.456 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
17:44:51.456 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
17:44:51.456 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
17:44:51.457 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
17:44:51.457 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
17:44:51.457 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
17:44:51.457 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
17:44:51.482 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 3
17:44:51.482 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 3
17:44:51.483 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 3
17:44:51.483 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_plans-0] for group xes_dev_study
17:44:51.483 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_classes-0] for group xes_dev_study
17:44:51.483 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_op_logs-0] for group xes_dev_study
17:44:51.483 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 3
17:44:51.484 [pool-2-thread-3] INFO  kafka - Rebalance happened study_xes_student_live_op_logs:0
17:44:51.484 [pool-2-thread-4] INFO  kafka - Rebalance happened study_xes_student_live_plans:0
17:44:51.484 [pool-2-thread-2] INFO  kafka - Rebalance happened study_xes_student_live_classes:0
17:44:51.486 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_courses-0] for group xes_dev_study
17:44:51.486 [pool-2-thread-1] INFO  kafka - Rebalance happened study_xes_student_courses:0
17:52:16.035 [elasticsearch[_client_][generic][T#1]] INFO  org.elasticsearch.client.transport.TransportClientNodesService - failed to get local cluster state for {#transport#-1}{a1xql99wQjCKfP7GDjEOjQ}{10.97.14.81}{10.97.14.81:9300}, disconnecting...
org.elasticsearch.transport.NodeDisconnectedException: [][10.97.14.81:9300][cluster:monitor/state] disconnected
19:03:44.429 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
19:03:44.433 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
19:03:45.455 [elasticsearch[_client_][management][T#1]] WARN  io.netty.util.internal.MacAddressUtil - Failed to find a usable hardware address from the network interfaces; using random bytes: aa:29:99:a6:17:f3:40:8d
19:03:45.799 [main] INFO  elasticsearch - Get client!
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - no modules loaded
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty3Plugin]
19:03:45.802 [main] INFO  org.elasticsearch.plugins.PluginsService - loaded plugin [org.elasticsearch.transport.Netty4Plugin]
19:03:45.884 [main] INFO  elasticsearch - Get client!
19:03:45.885 [main] INFO  kafka - threadnum: 4 and topicnum: 4
19:03:45.911 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

19:03:45.956 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
19:03:45.956 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
19:03:45.957 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

19:03:45.958 [pool-2-thread-1] INFO  kafka - Thread-48 Get kafka client!
19:03:45.970 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
19:03:45.970 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
19:03:45.971 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

19:03:45.974 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
19:03:45.974 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
19:03:45.974 [pool-2-thread-2] INFO  kafka - Thread-49 Get kafka client!
19:03:45.977 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.97.14.67:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = xes_dev_study
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

19:03:45.981 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
19:03:45.981 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
19:03:45.981 [pool-2-thread-3] INFO  kafka - Thread-50 Get kafka client!
19:03:45.982 [pool-2-thread-4] INFO  kafka - Thread-51 Get kafka client!
19:03:46.055 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
19:03:46.055 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
19:03:46.056 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
19:03:46.057 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 10.97.14.68:9092 (id: 2147483646 rack: null) for group xes_dev_study.
19:03:46.058 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
19:03:46.058 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
19:03:46.058 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.058 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.059 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
19:03:46.060 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.061 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group xes_dev_study
19:03:46.061 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.069 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group xes_dev_study
19:03:46.079 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 18
19:03:46.079 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 18
19:03:46.080 [pool-2-thread-3] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_op_logs-0] for group xes_dev_study
19:03:46.080 [pool-2-thread-4] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_plans-0] for group xes_dev_study
19:03:46.081 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 18
19:03:46.081 [pool-2-thread-3] INFO  kafka - Rebalance happened study_xes_student_live_op_logs:0
19:03:46.081 [pool-2-thread-4] INFO  kafka - Rebalance happened study_xes_student_live_plans:0
19:03:46.081 [pool-2-thread-2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_live_classes-0] for group xes_dev_study
19:03:46.081 [pool-2-thread-2] INFO  kafka - Rebalance happened study_xes_student_live_classes:0
19:03:46.083 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group xes_dev_study with generation 18
19:03:46.083 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [study_xes_student_courses-0] for group xes_dev_study
19:03:46.084 [pool-2-thread-1] INFO  kafka - Rebalance happened study_xes_student_courses:0
org.apache.kafka.clients.consumer.ConsumerRecords@73abf44b
19:03:46.152 [pool-2-thread-3] INFO  kafka - Thread-50: ConsumerRecord(topic = study_xes_student_live_op_logs, partition = 0, offset = 0, CreateTime = -1, serialized key size = 69, serialized value size = 391, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_live_op_logs","pk.id":18450}, value = {"database":"study","table":"xes_student_live_op_logs","type":"insert","ts":1505385672,"xid":72920872,"commit":true,"data":{"id":18450,"stu_id":11020,"stu_cou_id":4019020,"content":"{\"plan_id_from\":14917,\"plan_id_to\":\"14935\"}","controller":"App\\Component\\StuCourse\\StuCourse","action":"changeStuLivePlan","remark":"调场次","creater_id":11020,"create_time":"2017-09-14 18:41:25"}})
19:03:46.252 [pool-2-thread-3] INFO  elasticsearch - IndexResponse[index=xes_student_live_op_logs,type=study,id=18450,version=1,result=created,shards={"total":3,"successful":3,"failed":0}]
19:03:46.253 [pool-2-thread-3] INFO  time - xes_student_live_op_logs 18450 1354
19:03:46.253 [pool-2-thread-3] INFO  kafka - Thread-50: ConsumerRecord(topic = study_xes_student_live_op_logs, partition = 0, offset = 1, CreateTime = -1, serialized key size = 69, serialized value size = 391, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_live_op_logs","pk.id":18449}, value = {"database":"study","table":"xes_student_live_op_logs","type":"delete","ts":1505385775,"xid":72921465,"commit":true,"data":{"id":18449,"stu_id":11020,"stu_cou_id":4019020,"content":"{\"plan_id_from\":14935,\"plan_id_to\":\"14917\"}","controller":"App\\Component\\StuCourse\\StuCourse","action":"changeStuLivePlan","remark":"调场次","creater_id":11020,"create_time":"2017-09-14 17:32:38"}})
19:03:46.351 [pool-2-thread-3] INFO  elasticsearch - DeleteResponse[index=xes_student_live_op_logs,type=study,id=18449,version=1,result=not_found,shards=ShardInfo{total=3, successful=3, failures=[]}]
19:03:46.351 [pool-2-thread-3] INFO  time - xes_student_live_op_logs 18449 1251
19:03:46.352 [pool-2-thread-3] INFO  kafka - Thread-50: ConsumerRecord(topic = study_xes_student_live_op_logs, partition = 0, offset = 2, CreateTime = -1, serialized key size = 69, serialized value size = 391, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_live_op_logs","pk.id":18443}, value = {"database":"study","table":"xes_student_live_op_logs","type":"delete","ts":1505385775,"xid":72921466,"commit":true,"data":{"id":18443,"stu_id":11020,"stu_cou_id":4019020,"content":"{\"plan_id_from\":14917,\"plan_id_to\":\"14935\"}","controller":"App\\Component\\StuCourse\\StuCourse","action":"changeStuLivePlan","remark":"调场次","creater_id":11020,"create_time":"2017-09-13 21:13:15"}})
19:03:46.406 [pool-2-thread-3] INFO  elasticsearch - DeleteResponse[index=xes_student_live_op_logs,type=study,id=18443,version=2,result=deleted,shards=ShardInfo{total=3, successful=3, failures=[]}]
19:03:46.407 [pool-2-thread-3] INFO  time - xes_student_live_op_logs 18443 1251
19:03:46.407 [pool-2-thread-3] INFO  kafka - Thread-50: ConsumerRecord(topic = study_xes_student_live_op_logs, partition = 0, offset = 3, CreateTime = -1, serialized key size = 69, serialized value size = 395, headers = RecordHeaders(headers = [], isReadOnly = false), key = {"database":"study","table":"xes_student_live_op_logs","pk.id":11084}, value = {"database":"study","table":"xes_student_live_op_logs","type":"delete","ts":1505385775,"xid":72921467,"commit":true,"data":{"id":11084,"stu_id":11020,"stu_cou_id":4019020,"content":"{\"plan_id_from\":\"14917\",\"plan_id_to\":\"14935\"}","controller":"App\\Component\\StuCourse\\StuCourse","action":"changeStuLivePlan","remark":"调场次","creater_id":11020,"create_time":"2017-09-05 17:56:39"}})
19:03:46.453 [pool-2-thread-3] INFO  elasticsearch - DeleteResponse[index=xes_student_live_op_logs,type=study,id=11084,version=2,result=deleted,shards=ShardInfo{total=3, successful=3, failures=[]}]
19:03:46.453 [pool-2-thread-3] INFO  time - xes_student_live_op_logs 11084 1251
